{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08b88e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aafe370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\pulse-quest-env26\\samsum_train.csv\")   # id, dialogue, summary\n",
    "test_df  = pd.read_csv(r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\pulse-quest-env26\\samsum_test.csv\")    # id, dialogue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb01070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"dialogue\"] = train_df[\"dialogue\"].astype(str)\n",
    "train_df[\"summary\"]  = train_df[\"summary\"].astype(str)\n",
    "\n",
    "train_df = train_df.dropna(subset=[\"dialogue\", \"summary\"])\n",
    "train_df = train_df[train_df[\"dialogue\"].str.strip() != \"\"]\n",
    "train_df = train_df[train_df[\"summary\"].str.strip() != \"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3ebfa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b15ead11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6dabf89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    inputs = tokenizer(\n",
    "        batch[\"dialogue\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        text_target=batch[\"summary\"],\n",
    "        max_length=64,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8dcd4b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eadf8246d684b06b208e4ff5e895efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10312 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    load_from_cache_file=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80ad6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    report_to=[],\n",
    "    push_to_hub=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ddf63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajdw\\AppData\\Local\\Temp\\ipykernel_5332\\2416270126.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15468' max='15468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15468/15468 54:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.666900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.976600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.917600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.948700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.866500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.973100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.867200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.811300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.947400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.844400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.848800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.828100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.812200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.804400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.866600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.733500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.812400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.821200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.809500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.798700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.769900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.815800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.786100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.847300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.731600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.815700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.819500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.801800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.822900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.772600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.818400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.796100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.732900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.744500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.744700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.859300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.871300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.799900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.611100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.623800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.690700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.678200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.706700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.640500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.631100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.663400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.655800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.620400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.646200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.678100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.643600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.635900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.696100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.579300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.754400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.736400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.700200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.609100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.704700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.659400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.713500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.660700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.677800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.642900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.644700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.670200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.672400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.666300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.644100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.599600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.668900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.630600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.611100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.561100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.587000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.571100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.541300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.559500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.575700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.578100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.609300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.494600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.623900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.589700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.526600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.565800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.626500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.538700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.538100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.556400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.578100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.596500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.546400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.542400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.600200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.523300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.553800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.535800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13900</td>\n",
       "      <td>0.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14100</td>\n",
       "      <td>0.611300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.576200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14300</td>\n",
       "      <td>0.585200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.608600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.544500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.605100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>0.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.601500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14900</td>\n",
       "      <td>0.563200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.583400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15100</td>\n",
       "      <td>0.579500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.531100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15300</td>\n",
       "      <td>0.563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.506900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajdw\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15468, training_loss=0.7135738331370801, metrics={'train_runtime': 3249.4819, 'train_samples_per_second': 9.52, 'train_steps_per_second': 4.76, 'total_flos': 9431403536056320.0, 'train_loss': 0.7135738331370801, 'epoch': 3.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41e9a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Summaries generated and saved to test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# 1️⃣ Load test CSV\n",
    "test_df = pd.read_csv(r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\pulse-quest-env26\\samsum_test.csv\")  # contains 'id' and 'dialogue'\n",
    "\n",
    "# 2️⃣ Load trained model and tokenizer from checkpoint\n",
    "checkpoint_path = r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\Raj\\results\\checkpoint-15468\"  # replace xxxx with your latest checkpoint number\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_path)\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "# 3️⃣ Generate summaries\n",
    "summaries = []\n",
    "\n",
    "for text in test_df[\"dialogue\"]:\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    # move inputs to GPU if available\n",
    "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "    \n",
    "    # generate summary\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        num_beams=4,\n",
    "        max_length=60,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    summaries.append(summary)\n",
    "\n",
    "# 4️⃣ Save predictions to CSV\n",
    "test_df[\"summary\"] = summaries\n",
    "test_df.to_csv(\"test_predictions.csv\", index=False)\n",
    "\n",
    "print(\"✅ Summaries generated and saved to test_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "332c7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "test_df = pd.read_csv(r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\pulse-quest-env26\\samsum_test.csv\")             # original dialogues\n",
    "pred_df = pd.read_csv(r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\Raj\\test_predictions.csv\") # generated summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db8215b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping(dialogue_text):\n",
    "    \"\"\"\n",
    "    Maps placeholders like A, B in summary to actual names in dialogue\n",
    "    \"\"\"\n",
    "    # extract speaker placeholders in dialogue (assume format \"A:\", \"B:\", etc.)\n",
    "    placeholders = re.findall(r'(\\b[A-Z]\\b):', dialogue_text)\n",
    "    placeholders = list(dict.fromkeys(placeholders))  # remove duplicates, keep order\n",
    "    \n",
    "    # extract actual names (if real names are used, otherwise use same placeholders)\n",
    "    # For example, if dialogue already has actual names, you can replace this step\n",
    "    mapping = {}\n",
    "    for i, sp in enumerate(placeholders):\n",
    "        mapping[sp] = sp  # or map to actual names if known\n",
    "    return mapping\n",
    "\n",
    "# Apply mapping to all test dialogues\n",
    "test_df['mapping'] = test_df['dialogue'].apply(get_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86024049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final summaries saved with proper mapping\n"
     ]
    }
   ],
   "source": [
    "final_summaries = []\n",
    "\n",
    "for summary, mapping in zip(pred_df['summary'], test_df['mapping']):\n",
    "    for placeholder, actual in mapping.items():\n",
    "        summary = summary.replace(placeholder, actual)\n",
    "    final_summaries.append(summary)\n",
    "\n",
    "pred_df['summary'] = final_summaries\n",
    "pred_df.to_csv(\"test_predictions_mapped.csv\", index=False)\n",
    "\n",
    "print(\"✅ Final summaries saved with proper mapping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5e200e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load test dialogues and generated summaries\n",
    "test_df = pd.read_csv(r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\pulse-quest-env26\\samsum_test.csv\")          # has 'dialogue' with real names\n",
    "pred_df = pd.read_csv(\"test_predictions.csv\")  # has 'summary' with placeholders A/B\n",
    "\n",
    "def get_name_mapping(dialogue):\n",
    "    \"\"\"\n",
    "    Maps placeholder A/B in summary to actual speaker names in the dialogue\n",
    "    Returns a dict: {'A': 'Alice', 'B': 'Bob'}\n",
    "    \"\"\"\n",
    "    # Find all placeholders A, B, C etc. in dialogue\n",
    "    placeholders = re.findall(r'(\\b[A-Z]\\b):', dialogue)  # e.g., ['A', 'B']\n",
    "    \n",
    "    # Find all actual names in dialogue (text before ':')\n",
    "    names = re.findall(r'([A-Za-z]+):', dialogue)         # e.g., ['Alice', 'Bob']\n",
    "    \n",
    "    mapping = dict(zip(placeholders, names))\n",
    "    return mapping\n",
    "\n",
    "# Store mapping for each dialogue\n",
    "test_df['mapping'] = test_df['dialogue'].apply(get_name_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3004890e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Summaries saved with real names instead of A/B\n"
     ]
    }
   ],
   "source": [
    "final_summaries = []\n",
    "\n",
    "for summary, mapping in zip(pred_df['summary'], test_df['mapping']):\n",
    "    for placeholder, real_name in mapping.items():\n",
    "        summary = summary.replace(placeholder, real_name)\n",
    "    final_summaries.append(summary)\n",
    "\n",
    "pred_df['summary'] = final_summaries\n",
    "pred_df.to_csv(\"test_predictions_mapped.csv\", index=False)\n",
    "print(\"✅ Summaries saved with real names instead of A/B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c797ae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajdw\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73e7d9d5d5a4698a75df4cb5572da4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ROUGE scores on validation set:\n",
      "\n",
      "rouge1: 0.4550\n",
      "rouge2: 0.2375\n",
      "rougeL: 0.3841\n",
      "rougeLsum: 0.3841\n",
      "✅ Generated summaries saved to validation_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import evaluate\n",
    "\n",
    "# 1️⃣ Load validation data\n",
    "val_df = pd.read_csv(r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\samsum_data\\validation\\validation.csv\")  # must have columns: 'dialogue', 'summary' (reference)\n",
    "\n",
    "# 2️⃣ Load trained model checkpoint\n",
    "checkpoint_path = r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\Raj\\results\\checkpoint-15468\"  # replace with your checkpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_path)\n",
    "model.eval()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 3️⃣ Generate summaries for validation dialogues\n",
    "generated_summaries = []\n",
    "\n",
    "for dialogue in val_df['dialogue']:\n",
    "    inputs = tokenizer(dialogue, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        num_beams=4,\n",
    "        max_length=60,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_summaries.append(summary)\n",
    "\n",
    "# 4️⃣ Compute ROUGE metrics using evaluate\n",
    "references = val_df['summary'].tolist()\n",
    "predictions = generated_summaries\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "# 5️⃣ Print ROUGE scores\n",
    "print(\"✅ ROUGE scores on validation set:\\n\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# 6️⃣ Optional: save generated summaries\n",
    "val_df['predicted_summary'] = generated_summaries\n",
    "val_df.to_csv(\"validation_predictions.csv\", index=False)\n",
    "print(\"✅ Generated summaries saved to validation_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e971447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\Raj\\test_predictions_mapped.csv\")   # id, dialogue, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb5f12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_mapping(dialogue):\n",
    "    # Extract speaker names in order\n",
    "    names = re.findall(r'^(\\w+):', dialogue, flags=re.MULTILINE)\n",
    "\n",
    "    mapping = {}\n",
    "    if len(names) >= 1:\n",
    "        mapping['A'] = names[0]\n",
    "    if len(names) >= 2:\n",
    "        mapping['B'] = names[1]\n",
    "\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cfe5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_summary(row):\n",
    "    summary = row['summary']\n",
    "    dialogue = row['dialogue']\n",
    "\n",
    "    mapping = extract_name_mapping(dialogue)\n",
    "\n",
    "    for k, v in mapping.items():\n",
    "        summary = summary.replace(k, v)\n",
    "\n",
    "    return summary\n",
    "\n",
    "df['summary'] = df.apply(fix_summary, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050c1623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Names restored successfully\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"prediction_fixed.csv\", index=False)\n",
    "print(\"✅ Names restored successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57502b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_action_speaker(dialogue):\n",
    "    lines = dialogue.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if \":\" in line:\n",
    "            speaker, text = line.split(\":\", 1)\n",
    "            text = text.lower()\n",
    "            if any(p in text for p in [\"i want\", \"i will\", \"i plan\", \"i am going to\"]):\n",
    "                return speaker.strip()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d25360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_summary(dialogue, summary):\n",
    "    speaker = get_action_speaker(dialogue)\n",
    "    if not speaker:\n",
    "        return summary\n",
    "\n",
    "    # replace first name in summary with correct speaker\n",
    "    words = summary.split()\n",
    "    words[0] = speaker\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e90d58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\rajdw\\OneDrive\\Desktop\\PULSE QUEST\\Raj\\test_predictions_mapped.csv\")\n",
    "\n",
    "df[\"fixed_summary\"] = df.apply(\n",
    "    lambda x: fix_summary(x[\"dialogue\"], x[\"summary\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df.to_csv(\"prediction_fixed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a69fa173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"prediction_fixed.csv\")\n",
    "\n",
    "df = df.drop(columns=[\"dialogue\", \"summary\"])   # remove 2 columns\n",
    "\n",
    "df.to_csv(\"final_submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
